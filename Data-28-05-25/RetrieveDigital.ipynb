{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f33b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from fastapi import FastAPI\n",
    "#from dotenv import dotenv_values\n",
    "from pymongo import MongoClient\n",
    "from fastapi import APIRouter, Body, Request, Response, HTTPException, status\n",
    "#from fastapi.encoders import jsonable_encoder\n",
    "#from typing import List\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e633abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local functions\n",
    "def dbConnection(dbCFG):\n",
    "    # connect to base \n",
    "    app = FastAPI()\n",
    "    app.mongodb_client = MongoClient(dbCFG[\"ATLAS_URI\"])\n",
    "    app.database = app.mongodb_client[dbCFG[\"DB_NAME\"]]\n",
    "    router = APIRouter()\n",
    "    app.include_router(router)\n",
    "    #bdbtr = list(Request.app.database[\"bodybattery\"].find())\n",
    "    \n",
    "    app.mongodb_client.close()\n",
    "    client =  MongoClient(dbCFG[\"ATLAS_URI\"])\n",
    "    data = client[dbCFG[\"DB_NAME\"]]\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a733c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def retrieve(listVarNames, dbCFG, namecsv):\n",
    "    # 0. connect to dB. dictionary dbCFG provides all fields \n",
    "    db = dbConnection(dbCFG)\n",
    "    for collection_name in listVarNames:\n",
    "        collection = db[collection_name]\n",
    "        data = list(collection.find())\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # 2. save to CSV\n",
    "        csv_filename = f\"{namecsv}_{collection_name}.csv\"\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        \n",
    "        # 3. save to Pickle\n",
    "        pkl_filename = f\"{namecsv}_{collection_name}.pkl\"\n",
    "        with open(pkl_filename, 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "\n",
    "        print(f\"Saved {collection_name} to {csv_filename} and {pkl_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call retrieve\n",
    "pthLong = r\"mongodb://prodain:iprolep5isProdainigma@128.140.109.4:27017,49.13.200.206:27017,128.140.102.237:27017/iprolepsis?replicaSet=iprolepsisrs\"\n",
    " \n",
    "dbCFG = {\"ATLAS_URI\": pthLong,  \n",
    "        \"DB_NAME\": \"iprolepsis\" \n",
    "        }\n",
    "# tuples (collection, varname)\n",
    "tupsVarNames = [(\"bodybattery\", 'bodyBattery') , \n",
    "                ('wellness', 'steps'),\n",
    "                ('stresslevels','stressScore'),\n",
    "                ('heartratereadings','beatsPerMinute'),\n",
    "                ('wellness', 'activityType')\n",
    "                ]\n",
    "\n",
    "# keep just the collections\n",
    "listVarNames = [\"bodybattery\", \n",
    "                'wellness',\n",
    "                'stresslevels',\n",
    "                'heartratereadings',\n",
    "                ]\n",
    "\n",
    "namecsv = 'Mar28'\n",
    "retrieve(listVarNames, dbCFG, namecsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c735cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieving wellness...\n",
      "  Saved chunk 0 (100000 rows)\n",
      "  Saved chunk 1 (100000 rows)\n",
      "  Saved chunk 2 (100000 rows)\n",
      "  Saved chunk 3 (100000 rows)\n",
      "  Saved chunk 4 (100000 rows)\n",
      "  Saved chunk 5 (100000 rows)\n",
      "  Saved chunk 6 (100000 rows)\n",
      "  Saved chunk 7 (100000 rows)\n",
      "  Saved chunk 8 (100000 rows)\n",
      "  Saved chunk 9 (100000 rows)\n",
      "  Saved chunk 10 (100000 rows)\n",
      "  Saved chunk 11 (100000 rows)\n",
      "  Saved chunk 12 (100000 rows)\n",
      "  Saved chunk 13 (100000 rows)\n",
      "  Saved chunk 14 (100000 rows)\n",
      "  Saved chunk 15 (100000 rows)\n",
      "  Saved chunk 16 (100000 rows)\n",
      "  Saved chunk 17 (100000 rows)\n",
      "  Saved chunk 18 (100000 rows)\n",
      "  Saved chunk 19 (100000 rows)\n",
      "  Saved chunk 20 (100000 rows)\n",
      "  Saved chunk 21 (100000 rows)\n",
      "  Saved chunk 22 (100000 rows)\n",
      "  Saved chunk 23 (100000 rows)\n",
      "  Saved chunk 24 (100000 rows)\n",
      "  Saved chunk 25 (100000 rows)\n",
      "  Saved chunk 26 (100000 rows)\n",
      "  Saved chunk 27 (100000 rows)\n",
      "  Saved chunk 28 (100000 rows)\n",
      "  Saved chunk 29 (100000 rows)\n",
      "  Saved chunk 30 (100000 rows)\n",
      "  Saved chunk 31 (100000 rows)\n",
      "  Saved chunk 32 (100000 rows)\n",
      "  Saved chunk 33 (100000 rows)\n",
      "  Saved chunk 34 (100000 rows)\n",
      "  Saved chunk 35 (100000 rows)\n",
      "  Saved chunk 36 (100000 rows)\n",
      "  Saved chunk 37 (100000 rows)\n",
      "  Saved chunk 38 (100000 rows)\n",
      "  Saved chunk 39 (100000 rows)\n",
      "  Saved chunk 40 (100000 rows)\n",
      "  Saved chunk 41 (100000 rows)\n",
      "  Saved chunk 42 (100000 rows)\n",
      "  Saved chunk 43 (100000 rows)\n",
      "  Saved chunk 44 (100000 rows)\n",
      "  Saved chunk 45 (100000 rows)\n",
      "  Saved chunk 46 (100000 rows)\n",
      "  Saved chunk 47 (100000 rows)\n",
      "  Saved chunk 48 (100000 rows)\n",
      "  Saved chunk 49 (100000 rows)\n",
      "  Saved chunk 50 (100000 rows)\n",
      "  Saved chunk 51 (100000 rows)\n",
      "  Saved chunk 52 (100000 rows)\n",
      "  Saved chunk 53 (100000 rows)\n",
      "  Saved chunk 54 (100000 rows)\n",
      "  Saved chunk 55 (100000 rows)\n",
      "  Saved chunk 56 (100000 rows)\n",
      "  Saved chunk 57 (100000 rows)\n",
      "  Saved chunk 58 (100000 rows)\n",
      "  Saved chunk 59 (100000 rows)\n",
      "  Saved chunk 60 (100000 rows)\n",
      "  Saved chunk 61 (100000 rows)\n",
      "  Saved chunk 62 (100000 rows)\n",
      "  Saved chunk 63 (100000 rows)\n",
      "  Saved chunk 64 (100000 rows)\n",
      "  Saved chunk 65 (100000 rows)\n",
      "  Saved chunk 66 (100000 rows)\n",
      "  Saved chunk 67 (100000 rows)\n",
      "  Saved chunk 68 (100000 rows)\n",
      "  Saved chunk 69 (100000 rows)\n",
      "  Saved chunk 70 (100000 rows)\n",
      "  Saved chunk 71 (100000 rows)\n",
      "  Saved chunk 72 (100000 rows)\n",
      "  Saved chunk 73 (100000 rows)\n",
      "  Saved chunk 74 (100000 rows)\n",
      "  Saved chunk 75 (100000 rows)\n",
      "  Saved chunk 76 (100000 rows)\n",
      "  Saved chunk 77 (100000 rows)\n",
      "  Saved chunk 78 (100000 rows)\n",
      "  Saved chunk 79 (100000 rows)\n",
      "  Saved chunk 80 (100000 rows)\n",
      "  Saved chunk 81 (100000 rows)\n",
      "  Saved chunk 82 (100000 rows)\n",
      "  Saved chunk 83 (100000 rows)\n",
      "  Saved chunk 84 (100000 rows)\n",
      "  Saved chunk 85 (100000 rows)\n",
      "  Saved chunk 86 (100000 rows)\n",
      "  Saved chunk 87 (100000 rows)\n",
      "  Saved chunk 88 (100000 rows)\n",
      "  Saved chunk 89 (100000 rows)\n",
      "  Saved chunk 90 (100000 rows)\n",
      "  Saved chunk 91 (100000 rows)\n",
      "  Saved chunk 92 (100000 rows)\n",
      "  Saved chunk 93 (100000 rows)\n",
      "  Saved chunk 94 (100000 rows)\n",
      "  Saved chunk 95 (100000 rows)\n",
      "  Saved chunk 96 (100000 rows)\n",
      "  Saved chunk 97 (100000 rows)\n",
      "  Saved chunk 98 (100000 rows)\n",
      "  Saved chunk 99 (100000 rows)\n",
      "  Saved chunk 100 (100000 rows)\n",
      "  Saved chunk 101 (100000 rows)\n",
      "  Saved chunk 102 (100000 rows)\n",
      "  Saved chunk 103 (100000 rows)\n",
      "  Saved chunk 104 (100000 rows)\n",
      "  Saved chunk 105 (100000 rows)\n",
      "  Saved chunk 106 (100000 rows)\n",
      "  Saved chunk 107 (100000 rows)\n",
      "  Saved chunk 108 (100000 rows)\n",
      "  Saved chunk 109 (100000 rows)\n",
      "  Saved chunk 110 (100000 rows)\n",
      "  Saved chunk 111 (100000 rows)\n",
      "  Saved chunk 112 (100000 rows)\n",
      "  Saved chunk 113 (100000 rows)\n",
      "  Saved chunk 114 (100000 rows)\n",
      "  Saved chunk 115 (100000 rows)\n",
      "  Saved chunk 116 (100000 rows)\n",
      "  Saved chunk 117 (100000 rows)\n",
      "  Saved chunk 118 (100000 rows)\n",
      "  Saved chunk 119 (100000 rows)\n",
      "  Saved chunk 120 (100000 rows)\n",
      "  Saved chunk 121 (100000 rows)\n",
      "  Saved chunk 122 (100000 rows)\n",
      "  Saved chunk 123 (100000 rows)\n",
      "  Saved chunk 124 (100000 rows)\n",
      "  Saved chunk 125 (100000 rows)\n",
      "  Saved chunk 126 (100000 rows)\n",
      "  Saved chunk 127 (100000 rows)\n",
      "  Saved chunk 128 (100000 rows)\n",
      "  Saved chunk 129 (100000 rows)\n",
      "  Saved chunk 130 (100000 rows)\n",
      "  Saved chunk 131 (100000 rows)\n",
      "  Saved chunk 132 (100000 rows)\n",
      "  Saved chunk 133 (100000 rows)\n",
      "  Saved chunk 134 (100000 rows)\n",
      "  Saved chunk 135 (100000 rows)\n",
      "  Saved chunk 136 (100000 rows)\n",
      "  Saved chunk 137 (100000 rows)\n",
      "  Saved chunk 138 (100000 rows)\n",
      "  Saved chunk 139 (100000 rows)\n",
      "  Saved chunk 140 (100000 rows)\n",
      "  Saved chunk 141 (100000 rows)\n",
      "  Saved chunk 142 (100000 rows)\n",
      "  Saved chunk 143 (100000 rows)\n",
      "  Saved chunk 144 (100000 rows)\n",
      "  Saved chunk 145 (100000 rows)\n",
      "  Saved chunk 146 (100000 rows)\n",
      "  Saved chunk 147 (100000 rows)\n",
      "  Saved chunk 148 (100000 rows)\n",
      "  Saved chunk 149 (100000 rows)\n",
      "  Saved chunk 150 (100000 rows)\n",
      "  Saved chunk 151 (100000 rows)\n",
      "  Saved chunk 152 (100000 rows)\n",
      "  Saved chunk 153 (100000 rows)\n",
      "  Saved chunk 154 (100000 rows)\n",
      "  Saved chunk 155 (100000 rows)\n",
      "  Saved chunk 156 (100000 rows)\n",
      "  Saved chunk 157 (100000 rows)\n",
      "  Saved chunk 158 (100000 rows)\n",
      "  Saved chunk 159 (100000 rows)\n",
      "  Saved chunk 160 (100000 rows)\n",
      "  Saved chunk 161 (100000 rows)\n",
      "  Saved chunk 162 (100000 rows)\n",
      "  Saved chunk 163 (100000 rows)\n",
      "  Saved chunk 164 (100000 rows)\n",
      "  Saved chunk 165 (100000 rows)\n",
      "  Saved chunk 166 (100000 rows)\n",
      "  Saved chunk 167 (100000 rows)\n",
      "  Saved chunk 168 (100000 rows)\n",
      "  Saved chunk 169 (100000 rows)\n",
      "  Saved chunk 170 (100000 rows)\n",
      "  Saved chunk 171 (100000 rows)\n",
      "  Saved chunk 172 (100000 rows)\n",
      "  Saved chunk 173 (100000 rows)\n",
      "  Saved chunk 174 (100000 rows)\n",
      "  Saved chunk 175 (100000 rows)\n",
      "  Saved chunk 176 (100000 rows)\n",
      "  Saved chunk 177 (100000 rows)\n",
      "  Saved chunk 178 (100000 rows)\n",
      "  Saved chunk 179 (100000 rows)\n",
      "  Saved chunk 180 (100000 rows)\n",
      "  Saved chunk 181 (100000 rows)\n",
      "  Saved chunk 182 (100000 rows)\n",
      "  Saved chunk 183 (100000 rows)\n",
      "  Saved chunk 184 (100000 rows)\n",
      "  Saved chunk 185 (100000 rows)\n",
      "  Saved chunk 186 (100000 rows)\n",
      "  Saved chunk 187 (100000 rows)\n",
      "  Saved chunk 188 (100000 rows)\n",
      "  Saved chunk 189 (100000 rows)\n",
      "  Saved chunk 190 (100000 rows)\n",
      "  Saved chunk 191 (100000 rows)\n",
      "  Saved chunk 192 (100000 rows)\n",
      "  Saved chunk 193 (100000 rows)\n",
      "  Saved chunk 194 (100000 rows)\n",
      "  Saved chunk 195 (100000 rows)\n",
      "  Saved chunk 196 (100000 rows)\n",
      "  Saved chunk 197 (100000 rows)\n",
      "  Saved chunk 198 (100000 rows)\n",
      "  Saved chunk 199 (100000 rows)\n",
      "  Saved chunk 200 (100000 rows)\n",
      "  Saved chunk 201 (100000 rows)\n",
      "  Saved chunk 202 (100000 rows)\n",
      "  Saved chunk 203 (100000 rows)\n",
      "  Saved chunk 204 (100000 rows)\n",
      "  Saved chunk 205 (100000 rows)\n",
      "  Saved chunk 206 (100000 rows)\n",
      "  Saved chunk 207 (100000 rows)\n",
      "  Saved chunk 208 (100000 rows)\n",
      "  Saved chunk 209 (100000 rows)\n",
      "  Saved chunk 210 (100000 rows)\n",
      "  Saved chunk 211 (100000 rows)\n",
      "  Saved chunk 212 (100000 rows)\n",
      "  Saved chunk 213 (100000 rows)\n",
      "  Saved chunk 214 (100000 rows)\n",
      "  Saved chunk 215 (100000 rows)\n",
      "  Saved chunk 216 (100000 rows)\n",
      "  Saved chunk 217 (100000 rows)\n",
      "  Saved chunk 218 (100000 rows)\n",
      "  Saved chunk 219 (100000 rows)\n",
      "  Saved chunk 220 (100000 rows)\n",
      "  Saved chunk 221 (100000 rows)\n",
      "  Saved chunk 222 (100000 rows)\n",
      "  Saved chunk 223 (100000 rows)\n",
      "  Saved chunk 224 (100000 rows)\n",
      "  Saved chunk 225 (100000 rows)\n",
      "  Saved chunk 226 (100000 rows)\n",
      "  Saved chunk 227 (100000 rows)\n",
      "  Saved chunk 228 (100000 rows)\n",
      "  Saved chunk 229 (100000 rows)\n",
      "  Saved chunk 230 (100000 rows)\n",
      "  Saved chunk 231 (100000 rows)\n",
      "  Saved chunk 232 (100000 rows)\n",
      "  Saved chunk 233 (100000 rows)\n",
      "  Saved chunk 234 (100000 rows)\n",
      "  Saved chunk 235 (100000 rows)\n",
      "  Saved chunk 236 (100000 rows)\n",
      "  Saved chunk 237 (100000 rows)\n",
      "  Saved chunk 238 (100000 rows)\n",
      "  Saved chunk 239 (100000 rows)\n",
      "  Saved chunk 240 (100000 rows)\n",
      "  Saved chunk 241 (100000 rows)\n",
      "  Saved chunk 242 (100000 rows)\n",
      "  Saved chunk 243 (100000 rows)\n",
      "  Saved chunk 244 (100000 rows)\n",
      "  Saved chunk 245 (100000 rows)\n",
      "  Saved chunk 246 (100000 rows)\n",
      "  Saved chunk 247 (100000 rows)\n",
      "  Saved chunk 248 (100000 rows)\n",
      "  Saved chunk 249 (100000 rows)\n",
      "  Saved chunk 250 (100000 rows)\n",
      "  Saved chunk 251 (100000 rows)\n",
      "  Saved chunk 252 (100000 rows)\n",
      "  Saved chunk 253 (100000 rows)\n",
      "  Saved chunk 254 (100000 rows)\n",
      "  Saved chunk 255 (100000 rows)\n",
      "  Saved chunk 256 (100000 rows)\n",
      "  Saved chunk 257 (100000 rows)\n",
      "  Saved chunk 258 (100000 rows)\n",
      "  Saved final chunk 259 (9364 rows)\n",
      "✔ Done: wellness — 25909364 total rows saved.\n"
     ]
    }
   ],
   "source": [
    "#a faster approach to retrieve large chunks of data\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def dbConnection(cfg):\n",
    "    client = MongoClient(cfg[\"ATLAS_URI\"])\n",
    "    return client[cfg[\"DB_NAME\"]]\n",
    "\n",
    "def retrieve(collections, dbCFG, nameprefix, chunksize=100_000):\n",
    "    db = dbConnection(dbCFG)\n",
    "\n",
    "    for collection_name in collections:\n",
    "        print(f\"\\nRetrieving {collection_name}...\")\n",
    "        cursor = db[collection_name].find({}, projection={\"_id\": False}, batch_size=1000)\n",
    "\n",
    "        chunk = []\n",
    "        chunk_idx = 0\n",
    "        total_docs = 0\n",
    "\n",
    "        for doc in cursor:\n",
    "            chunk.append(doc)\n",
    "            if len(chunk) >= chunksize:\n",
    "                df = pd.DataFrame(chunk)\n",
    "                df.to_parquet(f\"{nameprefix}_{collection_name}_part{chunk_idx}.parquet\")\n",
    "                print(f\"  Saved chunk {chunk_idx} ({len(df)} rows)\")\n",
    "                total_docs += len(chunk)\n",
    "                chunk = []\n",
    "                chunk_idx += 1\n",
    "\n",
    "        # Final chunk\n",
    "        if chunk:\n",
    "            df = pd.DataFrame(chunk)\n",
    "            df.to_parquet(f\"{nameprefix}_{collection_name}_part{chunk_idx}.parquet\")\n",
    "            print(f\"  Saved final chunk {chunk_idx} ({len(df)} rows)\")\n",
    "            total_docs += len(chunk)\n",
    "\n",
    "        print(f\"✔ Done: {collection_name} — {total_docs} total rows saved.\")\n",
    "        cursor.close()\n",
    "\n",
    "# Usage\n",
    "# listVarNames = [\"bodybattery\",  \"stresslevels\", \"heartratereadings\", \"wellness\"]\n",
    "listVarNames = [\"wellness\"]\n",
    "\n",
    "dbCFG = {\n",
    "    \"ATLAS_URI\": \"mongodb://prodain:iprolep5isProdainigma@128.140.109.4:27017,49.13.200.206:27017,128.140.102.237:27017/iprolepsis?replicaSet=iprolepsisrs\",\n",
    "    \"DB_NAME\": \"iprolepsis\"\n",
    "}\n",
    "\n",
    "retrieve(listVarNames, dbCFG, \"Mar29\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20aedb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n",
      "Sampling 1000 from bodybattery...\n",
      "Retrieved 1000 from bodybattery in 0.57s\n",
      "Randomly sampled 1000 records from bodybattery and saved to Parquet and CSV.\n",
      "Sampling 1000 from wellness...\n",
      "Retrieved 1000 from wellness in 68.40s\n",
      "Randomly sampled 1000 records from wellness and saved to Parquet and CSV.\n",
      "Sampling 1000 from stresslevels...\n",
      "Retrieved 1000 from stresslevels in 68.92s\n",
      "Randomly sampled 1000 records from stresslevels and saved to Parquet and CSV.\n",
      "Sampling 1000 from heartratereadings...\n",
      "Retrieved 1000 from heartratereadings in 74.58s\n",
      "Randomly sampled 1000 records from heartratereadings and saved to Parquet and CSV.\n"
     ]
    }
   ],
   "source": [
    "# local functions\n",
    "def dbConnection(cfg):\n",
    "    client = MongoClient(cfg[\"ATLAS_URI\"])\n",
    "    return client[cfg[\"DB_NAME\"]], client\n",
    "\n",
    "def toyRetrieve(collections, dbCFG, nameprefix, sample_size=1000):\n",
    "    db, client = dbConnection(dbCFG)\n",
    "    print(\"Connected\")\n",
    "    import time\n",
    "    start = time.time()\n",
    "    with client.start_session() as session:\n",
    "        for collection_name in collections:\n",
    "            pipeline = [\n",
    "                {\"$sample\": {\"size\": sample_size}},\n",
    "                {\"$project\": {\"_id\": False}}\n",
    "            ]\n",
    "            print(f\"Sampling {sample_size} from {collection_name}...\")\n",
    "            cursor = db[collection_name].aggregate(pipeline, session=session)\n",
    "            \n",
    "            data = list(cursor)\n",
    "            print(f\"Retrieved {len(data)} from {collection_name} in {time.time() - start:.2f}s\")\n",
    "            if not data:\n",
    "                print(f\"No data returned from {collection_name}\")\n",
    "                continue\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_parquet(f\"{nameprefix}_{collection_name}_toy.parquet\")\n",
    "            df.to_csv(f\"{nameprefix}_{collection_name}_toy.csv\", index=False)\n",
    "\n",
    "            print(f\"Randomly sampled {len(df)} records from {collection_name} and saved to Parquet and CSV.\")\n",
    "\n",
    "\n",
    "toyRetrieve(listVarNames, dbCFG, \"Toy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36479c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bodybattery\n",
      "  Document count: N/A\n",
      "  Size (MB): 97.97\n",
      "  Storage size (MB): 32.01\n",
      "  Avg doc size (KB): 0.00\n",
      "  Indexes (MB): 5.59\n",
      "\n",
      "stresslevels\n",
      "  Document count: N/A\n",
      "  Size (MB): 108.36\n",
      "  Storage size (MB): 52.20\n",
      "  Avg doc size (KB): 0.00\n",
      "  Indexes (MB): 5.54\n",
      "\n",
      "wellness\n",
      "  Document count: 25339441\n",
      "  Size (MB): 8124.88\n",
      "  Storage size (MB): 1152.06\n",
      "  Avg doc size (KB): 0.31\n",
      "  Indexes (MB): 1198.37\n",
      "\n",
      "heartratereadings\n",
      "  Document count: N/A\n",
      "  Size (MB): 116.67\n",
      "  Storage size (MB): 49.95\n",
      "  Avg doc size (KB): 0.00\n",
      "  Indexes (MB): 7.36\n"
     ]
    }
   ],
   "source": [
    "def profile_collection_sizes(db, collections):\n",
    "    for name in collections:\n",
    "        try:\n",
    "            stats = db.command({\"collStats\": name})\n",
    "            \n",
    "            if stats.get(\"ok\", 0) != 1:\n",
    "                print(f\"{name} → collStats failed: {stats.get('errmsg', 'Unknown error')}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n{name}\")\n",
    "            print(f\"  Document count: {stats.get('count', 'N/A')}\")\n",
    "            print(f\"  Size (MB): {stats.get('size', 0) / 1e6:.2f}\")\n",
    "            print(f\"  Storage size (MB): {stats.get('storageSize', 0) / 1e6:.2f}\")\n",
    "            print(f\"  Avg doc size (KB): {stats.get('avgObjSize', 0) / 1024:.2f}\")\n",
    "            print(f\"  Indexes (MB): {stats.get('totalIndexSize', 0) / 1e6:.2f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving stats for '{name}': {e}\")\n",
    "\n",
    "\n",
    "db, _ = dbConnection(dbCFG)\n",
    "profile_collection_sizes(db, [\"bodybattery\", \"stresslevels\", \"wellness\",'heartratereadings'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean raw data steps\n",
    "\n",
    "# BatterySaver Periods?\n",
    "\n",
    "# filter step rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DYNAMIC TSFresh SETTINGS ===\n",
    "def get_fc_parameters(modality):\n",
    "    if modality in ['steps_summary', 'steps_hourly', 'steps_daily', 'walking_time']:\n",
    "        return {\n",
    "            'sum_values': None,\n",
    "            'mean': None,\n",
    "            'variance': None,\n",
    "            'standard_deviation': None,\n",
    "            'linear_trend': [{\"attr\": attr} for attr in ['intercept', 'slope', 'rvalue']]\n",
    "        }\n",
    "    elif modality == 'physical_activity', 'sedentary_prop':\n",
    "        return {\n",
    "            'mean': None,\n",
    "            'median': None,\n",
    "            'variance': None,\n",
    "            'percentage_of_reoccurring_values_to_all_values': None\n",
    "        }\n",
    "    else: #let bdybattery, stresscore, bpm be processed like this\n",
    "        return {\n",
    "            'sum_values': None,\n",
    "            'mean': None,\n",
    "            'variance': None,\n",
    "            'standard_deviation': None,\n",
    "            'linear_trend': [{\"attr\": attr} for attr in ['intercept', 'slope', 'rvalue']]\n",
    "        }\n",
    "custom_fc_parameters = get_fc_parameters(modality)\n",
    "extracted = extract_features(\n",
    "        df_ts,\n",
    "        column_id='id',\n",
    "        column_sort='time',\n",
    "        column_value=\"value\"\n",
    "        default_fc_parameters=custom_fc_parameters,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adm explore PDPID data",
   "language": "python",
   "name": "adm-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
